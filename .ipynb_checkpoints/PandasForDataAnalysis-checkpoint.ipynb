{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ab210b",
   "metadata": {},
   "source": [
    "# Pandas for Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b4d103",
   "metadata": {},
   "source": [
    "## Creating a DataFrame\n",
    "\n",
    "- A DataFrame is an object that stores data as rows and columns. You can think of a DataFrame as a spreadsheet or as a SQL table. \n",
    "- Each column has a name, which is a string. \n",
    "- Each row has an index, which is an integer. \n",
    "- You can pass in a dictionary to `pd.DataFrame()`. Each key is a column name and each value is a list of column values. \n",
    "- The columns must all be the same length or you will get an error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb02d1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student ID Student Name   Color\n",
      "0           1         Alex    blue\n",
      "1           2       Brayan   green\n",
      "2           3    Stephanie  yellow\n",
      "3           4       Néstor     red\n",
      "4           5        Jorge   black\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.DataFrame({\n",
    "  'Student ID': [1, 2, 3, 4, 5],\n",
    "  'Student Name': ['Alex', 'Brayan', 'Stephanie', 'Néstor', 'Jorge'],\n",
    "  'Color': ['blue', 'green', 'yellow', 'red', 'black']\n",
    "})\n",
    "\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29ac943",
   "metadata": {},
   "source": [
    "You can also add data using lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08a24c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Student ID       Name   Color\n",
      "0           1       Alex    blue\n",
      "1           2     Brayan   green\n",
      "2           3  Stephanie  yellow\n",
      "3           4     Néstor     red\n",
      "4           5      Jorge   black\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame([\n",
    "  [1, 'Alex', 'blue'],\n",
    "  [2, 'Brayan', 'green'],\n",
    "  [3, 'Stephanie', 'yellow'],\n",
    "  [4, 'Néstor', 'red'],\n",
    "  [5, 'Jorge', 'black'],\n",
    "],\n",
    "  columns=[\n",
    "    'Student ID', 'Name', 'Color'\n",
    "  ])\n",
    "\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6089214",
   "metadata": {},
   "source": [
    "## Comma Separated Variables (CSV)\n",
    "\n",
    "- Most of the time, we’ll be working with datasets that already exist. \n",
    "- One of the most common formats for big datasets is the CSV (comma separated values) \n",
    "- The first row of a CSV contains column headings. \n",
    "- All subsequent rows contain values. \n",
    "- Each column heading and each variable is separated by a comma:\n",
    "- When you have data in a CSV, you can load it into a DataFrame in Pandas using `.read_csv()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d0d15ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             name cake_flavor frosting_flavor             topping\n",
      "0  Chocolate Cake   chocolate       chocolate  chocolate shavings\n",
      "1   Birthday Cake     vanilla         vanilla   rainbow sprinkles\n",
      "2     Carrot Cake      carrot    cream cheese             almonds\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('cupcakes.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e175d8d",
   "metadata": {},
   "source": [
    "- The method `.head()` gives the first 5 rows of a DataFrame. \n",
    "- If you want to see more rows, you can pass in the positional argument `n`. \n",
    "- The method `df.info()` gives some statistics for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ade02b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                       name   genre  year  imdb_rating\n",
      "0   1                                     Avatar  action  2009          7.9\n",
      "1   2                             Jurassic World  action  2015          7.3\n",
      "2   3                               The Avengers  action  2012          8.1\n",
      "3   4                            The Dark Knight  action  2008          9.0\n",
      "4   5  Star Wars: Episode I - The Phantom Menace  action  1999          6.6\n",
      "5   6                                  Star Wars  action  1977          8.7\n",
      "6   7                    Avengers: Age of Ultron  action  2015          7.9\n",
      "7   8                      The Dark Knight Rises  action  2012          8.5\n",
      "8   9  Pirates of the Caribbean: Dead Mans Chest  action  2006          7.3\n",
      "9  10                                 Iron Man 3  action  2013          7.3\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 220 entries, 0 to 219\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   id           220 non-null    int64  \n",
      " 1   name         220 non-null    object \n",
      " 2   genre        220 non-null    object \n",
      " 3   year         220 non-null    int64  \n",
      " 4   imdb_rating  220 non-null    float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 8.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('imdb.csv')\n",
    "print(df.head(10))\n",
    "print('\\n')\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd41ae87",
   "metadata": {},
   "source": [
    "## Select Columns\n",
    "\n",
    "There are two possible syntaxes for selecting all values from a column:\n",
    "\n",
    "1. Select the column as if you were selecting a value from a dictionary using a key. \n",
    "2. If the name of a column follows all of the rules for a variable name (doesn’t start with a number, doesn’t contain spaces or special characters, etc.), then you can select it using the dot notation\n",
    "\n",
    "When we select a single column, the result is called a _Series_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf78e107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of a column: <class 'pandas.core.series.Series'>\n",
      "Type of the table: <class 'pandas.core.frame.DataFrame'>\n",
      "Head of the table: \n",
      "0    100\n",
      "1     45\n",
      "2     96\n",
      "3     80\n",
      "4     54\n",
      "Name: clinic_north, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([\n",
    "  ['January', 100, 100, 23, 100],\n",
    "  ['February', 51, 45, 145, 45],\n",
    "  ['March', 81, 96, 65, 96],\n",
    "  ['April', 80, 80, 54, 180],\n",
    "  ['May', 51, 54, 54, 154],\n",
    "  ['June', 112, 109, 79, 129]],\n",
    "  columns=['month', 'clinic_east',\n",
    "           'clinic_north', 'clinic_south',\n",
    "           'clinic_west']\n",
    ")\n",
    "\n",
    "clinic_north = df['clinic_north']\n",
    "print(f'Type of a column: {type(clinic_north)}')\n",
    "print(f'Type of the table: {type(df)}')\n",
    "print(f'Head of the table: \\n{clinic_north.head()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba938d9",
   "metadata": {},
   "source": [
    "## Selecting Multiple Columns\n",
    "\n",
    "To select two or more columns from a DataFrame, we use a list of the column names. \n",
    "**Note:** Make sure that you have a double set of brackets (`[[]]`), or this command won’t work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f38132b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   clinic_north  clinic_south\n",
      "0           100            23\n",
      "1            45           145\n",
      "2            96            65\n",
      "3            80            54\n",
      "4            54            54\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([\n",
    "  ['January', 100, 100, 23, 100],\n",
    "  ['February', 51, 45, 145, 45],\n",
    "  ['March', 81, 96, 65, 96],\n",
    "  ['April', 80, 80, 54, 180],\n",
    "  ['May', 51, 54, 54, 154],\n",
    "  ['June', 112, 109, 79, 129]],\n",
    "  columns=['month', 'clinic_east',\n",
    "           'clinic_north', 'clinic_south',\n",
    "           'clinic_west']\n",
    ")\n",
    "\n",
    "clinic_north_south = df[['clinic_north', 'clinic_south']]\n",
    "print(type(clinic_north_south))\n",
    "print(clinic_north_south.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d004dc40",
   "metadata": {},
   "source": [
    "## Select Rows\n",
    "\n",
    "- DataFrames are zero-indexed, meaning that we start with the 0th row and count up from there.\n",
    "- We select a row using '.iloc'\n",
    "- When we select a single row, the result is a Series (just like when we select a single column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b125c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      month  clinic_east  clinic_north  clinic_south  clinic_west\n",
      "0   January          100           100            23          100\n",
      "1  February           51            45           145           45\n",
      "2     March           81            96            65           96\n",
      "3     April           80            80            54          180\n",
      "4       May           51            54            54          154\n",
      "\n",
      "\n",
      "month           March\n",
      "clinic_east        81\n",
      "clinic_north       96\n",
      "clinic_south       65\n",
      "clinic_west        96\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([\n",
    "  ['January', 100, 100, 23, 100],\n",
    "  ['February', 51, 45, 145, 45],\n",
    "  ['March', 81, 96, 65, 96],\n",
    "  ['April', 80, 80, 54, 180],\n",
    "  ['May', 51, 54, 54, 154],\n",
    "  ['June', 112, 109, 79, 129]],\n",
    "  columns=['month', 'clinic_east',\n",
    "           'clinic_north', 'clinic_south',\n",
    "           'clinic_west'])\n",
    "\n",
    "march = df.iloc[2]\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print(march.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3143c525",
   "metadata": {},
   "source": [
    "## Selecting Multiple Rows\n",
    "\n",
    "You can also select multiple rows from a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0a770ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      month  clinic_east  clinic_north  clinic_south  clinic_west\n",
      "0   January          100           100            23          100\n",
      "1  February           51            45           145           45\n",
      "2     March           81            96            65           96\n",
      "3     April           80            80            54          180\n",
      "4       May           51            54            54          154\n",
      "5      June          112           109            79          129\n",
      "\n",
      "\n",
      "   month  clinic_east  clinic_north  clinic_south  clinic_west\n",
      "3  April           80            80            54          180\n",
      "4    May           51            54            54          154\n",
      "5   June          112           109            79          129\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([\n",
    "  ['January', 100, 100, 23, 100],\n",
    "  ['February', 51, 45, 145, 45],\n",
    "  ['March', 81, 96, 65, 96],\n",
    "  ['April', 80, 80, 54, 180],\n",
    "  ['May', 51, 54, 54, 154],\n",
    "  ['June', 112, 109, 79, 129]],\n",
    "  columns=['month', 'clinic_east',\n",
    "           'clinic_north', 'clinic_south',\n",
    "           'clinic_west']\n",
    ")\n",
    "\n",
    "april_may_june = df.iloc[3:6]\n",
    "print(df)\n",
    "print('\\n')\n",
    "print(april_may_june)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086be25",
   "metadata": {},
   "source": [
    "## Select Rows with Logic\n",
    "\n",
    "- You can select a subset of a DataFrame by using logical statements.\n",
    "- In Python, `==` is how we test if a value is exactly equal to another value.\n",
    "\n",
    "We can use other logical statements, such as:\n",
    "\n",
    "- Greater Than, `>` \n",
    "- Less Than, `<` \n",
    "- Not Equal, `!=` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e6711ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame: \n",
      "\n",
      "      month  clinic_east  clinic_north  clinic_south  clinic_west\n",
      "0   January          100           100            23          100\n",
      "1  February           51            45           145           45\n",
      "2     March           81            96            65           96\n",
      "3     April           80            80            54          180\n",
      "4       May           51            54            54          154\n",
      "5      June          112           109            79          129\n",
      "\n",
      "Filter:\n",
      "\n",
      "     month  clinic_east  clinic_north  clinic_south  clinic_west\n",
      "0  January          100           100            23          100\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([\n",
    "  ['January', 100, 100, 23, 100],\n",
    "  ['February', 51, 45, 145, 45],\n",
    "  ['March', 81, 96, 65, 96],\n",
    "  ['April', 80, 80, 54, 180],\n",
    "  ['May', 51, 54, 54, 154],\n",
    "  ['June', 112, 109, 79, 129]],\n",
    "  columns=['month', 'clinic_east',\n",
    "           'clinic_north', 'clinic_south',\n",
    "           'clinic_west'])\n",
    "print('DataFrame: \\n')\n",
    "print(df)\n",
    "january = df[df.month == 'January']\n",
    "print('\\nFilter:\\n')\n",
    "print(january)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eab9e51",
   "metadata": {},
   "source": [
    "- You can also combine multiple logical statements, as long as each statement is in parentheses.\n",
    "- In Python, `|` means “or” and `&` means “and”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13215898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     month  clinic_east  clinic_north  clinic_south  clinic_west\n",
      "0  January          100           100            23          100\n",
      "2    March           81            96            65           96\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([\n",
    "  ['January', 100, 100, 23, 100],\n",
    "  ['February', 51, 45, 145, 45],\n",
    "  ['March', 81, 96, 65, 96],\n",
    "  ['April', 80, 80, 54, 180],\n",
    "  ['May', 51, 54, 54, 154],\n",
    "  ['June', 112, 109, 79, 129]],\n",
    "  columns=['month', 'clinic_east',\n",
    "           'clinic_north', 'clinic_south',\n",
    "           'clinic_west'])\n",
    "\n",
    "march_april = df[(df.month == 'January') | (df.month == 'March')]\n",
    "\n",
    "print(march_april)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da23eb5b",
   "metadata": {},
   "source": [
    "We could use the `isin` command to check that `df.name` is one of a list of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97afa348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     month  clinic_east  clinic_north  clinic_south  clinic_west\n",
      "0  January          100           100            23          100\n",
      "2    March           81            96            65           96\n",
      "4      May           51            54            54          154\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([\n",
    "  ['January', 100, 100, 23, 100],\n",
    "  ['February', 51, 45, 145, 45],\n",
    "  ['March', 81, 96, 65, 96],\n",
    "  ['April', 80, 80, 54, 180],\n",
    "  ['May', 51, 54, 54, 154],\n",
    "  ['June', 112, 109, 79, 129]],\n",
    "  columns=['month', 'clinic_east',\n",
    "           'clinic_north', 'clinic_south',\n",
    "           'clinic_west'])\n",
    "\n",
    "january_march_may = df[df.month.isin(['January', 'March', 'May'])]\n",
    "print(january_march_may)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbd38d3",
   "metadata": {},
   "source": [
    "## Setting indices\n",
    "\n",
    "- When we select a subset of a DataFrame using logic, we end up with non-consecutive indices. This is inelegant and makes it hard to use `.iloc()`.\n",
    "- We can fix this using the method `.reset_index()`. \n",
    "- If we use the command `df.reset_index()`, we get a new DataFrame with a new set of indices.\n",
    "- The old indices move into a new column `'index'`. Unless you need those values for something special, it’s probably better to use the keyword `drop=True` so that you don’t end up with that extra column. \n",
    "- We usually just want to modify our existing DataFrame. If we use the keyword `inplace=True` we can just modify our existing DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad547932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original df2: \n",
      "      month  clinic_east  clinic_north  clinic_south  clinic_west\n",
      "1  February           51            45           145           45\n",
      "3     April           80            80            54          180\n",
      "5      June          112           109            79          129\n",
      "\n",
      "Reset df2 index: \n",
      "      month  clinic_east  clinic_north  clinic_south  clinic_west\n",
      "0  February           51            45           145           45\n",
      "1     April           80            80            54          180\n",
      "2      June          112           109            79          129\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([\n",
    "  ['January', 100, 100, 23, 100],\n",
    "  ['February', 51, 45, 145, 45],\n",
    "  ['March', 81, 96, 65, 96],\n",
    "  ['April', 80, 80, 54, 180],\n",
    "  ['May', 51, 54, 54, 154],\n",
    "  ['June', 112, 109, 79, 129]],\n",
    "  columns=['month', 'clinic_east',\n",
    "           'clinic_north', 'clinic_south',\n",
    "           'clinic_west']\n",
    ")\n",
    "\n",
    "df2 = df.iloc[[1, 3, 5]]\n",
    "print('\\nOriginal df2: ')\n",
    "print(df2)\n",
    "df2.reset_index(inplace=True, drop=True)\n",
    "print('\\nReset df2 index: ')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ba4b8d",
   "metadata": {},
   "source": [
    "## Adding a Column\n",
    "\n",
    "Sometimes, we want to add a column to an existing DataFrame. We might want to add new information or perform a calculation based on the data that we already have.\n",
    "\n",
    "One way that we can add a new column is by giving a list of the same length as the existing DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34313e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DF:\n",
      "    Product ID   Description  Cost to Manufacture  Price\n",
      "0           1  3 inch screw                  0.5   0.75\n",
      "1           2   2 inch nail                  0.1   0.25\n",
      "2           3        hammer                  3.0   5.50\n",
      "3           4   screwdriver                  2.5   3.00\n",
      "\n",
      "DF after adding column:\n",
      "    Product ID   Description  Cost to Manufacture  Price Sold in Bulk?\n",
      "0           1  3 inch screw                  0.5   0.75           Yes\n",
      "1           2   2 inch nail                  0.1   0.25           Yes\n",
      "2           3        hammer                  3.0   5.50            No\n",
      "3           4   screwdriver                  2.5   3.00            No\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([\n",
    "  [1, '3 inch screw', 0.5, 0.75],\n",
    "  [2, '2 inch nail', 0.10, 0.25],\n",
    "  [3, 'hammer', 3.00, 5.50],\n",
    "  [4, 'screwdriver', 2.50, 3.00]\n",
    "],\n",
    "  columns=['Product ID', 'Description', 'Cost to Manufacture', 'Price']\n",
    ")\n",
    "\n",
    "print(f'Original DF:\\n {df}')\n",
    "df['Sold in Bulk?'] = ['Yes', 'Yes', 'No', 'No']\n",
    "print(f'\\nDF after adding column:\\n {df}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e4941c",
   "metadata": {},
   "source": [
    "We can also add a new column that is the same for all rows in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2b9ca53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Product ID   Description  Cost to Manufacture  Price Is taxed?\n",
      "0           1  3 inch screw                  0.5   0.75       Yes\n",
      "1           2   2 inch nail                  0.1   0.25       Yes\n",
      "2           3        hammer                  3.0   5.50       Yes\n",
      "3           4   screwdriver                  2.5   3.00       Yes\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([\n",
    "  [1, '3 inch screw', 0.5, 0.75],\n",
    "  [2, '2 inch nail', 0.10, 0.25],\n",
    "  [3, 'hammer', 3.00, 5.50],\n",
    "  [4, 'screwdriver', 2.50, 3.00]\n",
    "],\n",
    "  columns=['Product ID', 'Description', 'Cost to Manufacture', 'Price']\n",
    ")\n",
    "\n",
    "df['Is taxed?'] = 'Yes'\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3667f24",
   "metadata": {},
   "source": [
    "You can add a new column by performing a function on the existing columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b38b7301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Product ID   Description  Cost to Manufacture  Price  Margin\n",
      "0           1  3 inch screw                  0.5   0.75    0.25\n",
      "1           2   2 inch nail                  0.1   0.25    0.15\n",
      "2           3        hammer                  3.0   5.50    2.50\n",
      "3           4   screwdriver                  2.5   3.00    0.50\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([\n",
    "  [1, '3 inch screw', 0.5, 0.75],\n",
    "  [2, '2 inch nail', 0.10, 0.25],\n",
    "  [3, 'hammer', 3.00, 5.50],\n",
    "  [4, 'screwdriver', 2.50, 3.00]\n",
    "],\n",
    "  columns=['Product ID', 'Description', 'Cost to Manufacture', 'Price']\n",
    ")\n",
    "\n",
    "df['Margin'] = df.Price - df['Cost to Manufacture']\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3c3545",
   "metadata": {},
   "source": [
    "## Column Operations\n",
    "\n",
    "Often, the column that we want to add is related to existing columns, but requires a calculation more complex than multiplication or addition.\n",
    "\n",
    "We can use the `apply` function to apply a function to every value in a particular column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6847aa3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Name                 Email Lowercase Name\n",
      "0  JOHN SMITH  john.smith@gmail.com     john smith\n",
      "1    Jane Doe        jdoe@yahoo.com       jane doe\n",
      "2   joe schmo  joeschmo@hotmail.com      joe schmo\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([\n",
    "  ['JOHN SMITH', 'john.smith@gmail.com'],\n",
    "  ['Jane Doe', 'jdoe@yahoo.com'],\n",
    "  ['joe schmo', 'joeschmo@hotmail.com']\n",
    "],\n",
    "columns=['Name', 'Email'])\n",
    "\n",
    "df['Lowercase Name'] = df.Name.apply(str.lower)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a541521d",
   "metadata": {},
   "source": [
    "## Lambda Function\n",
    "\n",
    "A _lambda function_ is a way of defining a function in a single line of code. Usually, we would assign them to a variable.\n",
    "\n",
    "For example, the following lambda function multiplies a number by 2 and then adds 3:\n",
    "\n",
    "```python\n",
    "mylambda = lambda x: (x * 2) + 3\n",
    "print(mylambda(5))\n",
    "```\n",
    "\n",
    "The output:\n",
    "\n",
    "```\n",
    "13\n",
    "```\n",
    "\n",
    "Let’s break this syntax down:\n",
    "\n",
    "1. The function is stored in a variable called `mylambda`\n",
    "2. `lambda` declares that this is a lambda function (if you are familiar with normal Python functions, this is similar to how we use def to declare a function)\n",
    "3. `x` is what we call the input we are passing into `mylambda`\n",
    "4. We are returning `(x * 2) + 3` (with normal Python functions, we use the keyword return)\n",
    "\n",
    "Lambda functions only work if we’re just doing a one line command. If we wanted to write something longer, we’d need a more complex function. Lambda functions are great when you need to use a function once. Because you aren’t defining a function, the reusability aspect functions is not present with lambda functions. By saving the work of defining a function, a lambda function allows us to efficiently run an expression and produce an output for a specific task, such as defining a column in a table, or populating information in a dictionary.\n",
    "\n",
    "Lambda functions work with all types of variables, not just integers! Here is an example that takes in a string, assigns it to the temporary variable x, and then converts it into lowercase:\n",
    "\n",
    "```python\n",
    "stringlambda = lambda x: x.lower()\n",
    "print(stringlambda(\"Oh Hi Mark!\"))\n",
    "```\n",
    "\n",
    "The output:\n",
    "\n",
    "```\n",
    "\"oh hi mark!\"\n",
    "```\n",
    "\n",
    "We can make our lambdas more complex by using a modified form of an if statement.\n",
    "\n",
    "Suppose we want to pay workers time-and-a-half for overtime (any work above 40 hours per week). The following function will convert the number of hours into time-and-a-half hours using an if statement:\n",
    "\n",
    "```python\n",
    "def myfunction(x):\n",
    "    if x > 40:\n",
    "        return 40 + (x - 40) * 1.50\n",
    "    else:\n",
    "        return x\n",
    "```\n",
    "\n",
    "Below is a lambda function that does the same thing:\n",
    "\n",
    "```python\n",
    "myfunction = lambda x: 40 + (x - 40) * 1.50 if x > 40 else x\n",
    "```\n",
    "\n",
    "In general, the syntax for an if function in a lambda function is:\n",
    "\n",
    "```\n",
    "lambda x: [OUTCOME IF TRUE] if [CONDITIONAL] else [OUTCOME IF FALSE]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ec47a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T!\n"
     ]
    }
   ],
   "source": [
    "mylambda = lambda my_str: my_str[0] + my_str[-1]\n",
    "print(mylambda('This is great!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c69a651a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to BattleCity!\n",
      "You must be over 13\n"
     ]
    }
   ],
   "source": [
    "mylambda = lambda age: 'Welcome to BattleCity!' if age >= 13 else 'You must be over 13'\n",
    "print(mylambda(25))\n",
    "print(mylambda(12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f794b3eb",
   "metadata": {},
   "source": [
    "## Applying a Lambda to a Column\n",
    "\n",
    "In Pandas, we often use lambda functions to perform complex operations on columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "912dda37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id               name  hourly_wage  hours_worked  last_name\n",
      "0   10310      Lauren Durham           19            43     Durham\n",
      "1   18656      Grace Sellers           17            40    Sellers\n",
      "2   61254  Shirley Rasmussen           16            30  Rasmussen\n",
      "3   16886        Brian Rojas           18            47      Rojas\n",
      "4   89010    Samantha Mosley           11            38     Mosley\n",
      "5   87246       Louis Guzman           14            39     Guzman\n",
      "6   20578     Denise Mcclure           15            40    Mcclure\n",
      "7   12869      James Raymond           15            32    Raymond\n",
      "8   53461       Noah Collier           18            35    Collier\n",
      "9   14746    Donna Frederick           20            41  Frederick\n",
      "10  71127       Shirley Beck           14            32       Beck\n",
      "11  92522    Christina Kelly            8            44      Kelly\n",
      "12  22447        Brian Noble           11            39      Noble\n",
      "13  61654          Randy Key           16            38        Key\n",
      "14  16988      Diana Stewart           14            48    Stewart\n",
      "15  68619       Timothy Sosa           14            42       Sosa\n",
      "16  59949      Betty Skinner           11            48    Skinner\n",
      "17  81418      Janet Maxwell           12            38    Maxwell\n",
      "18  27267   Madison Johnston           20            37   Johnston\n",
      "19  19985   Virginia Nichols           13            49    Nichols\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('employees.csv')\n",
    "\n",
    "get_last_name = lambda full_name: full_name.split()[1]\n",
    "df['last_name'] = df.name.apply(get_last_name)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83c604c",
   "metadata": {},
   "source": [
    "## Applying a Lambda to a Row\n",
    "\n",
    "We can also operate on multiple columns at once. If we use `apply` without specifying a single column and add the argument `axis=1`, the input to our lambda function will be an entire row, not a column. To access particular values of the row, we use the syntax `row.column_name` or `row[‘column_name’]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "640b85b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id               name  hourly_wage  hours_worked  total_earned\n",
      "0  10310      Lauren Durham           19            43         845.5\n",
      "1  18656      Grace Sellers           17            40         680.0\n",
      "2  61254  Shirley Rasmussen           16            30         480.0\n",
      "3  16886        Brian Rojas           18            47         909.0\n",
      "4  89010    Samantha Mosley           11            38         418.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('employees.csv')\n",
    "\n",
    "total_earned = lambda row: (row.hourly_wage * 40) + ((row.hourly_wage * 1.5) * (row.hours_worked - 40)) if row.hours_worked > 40 \\\n",
    "  else row.hourly_wage * row.hours_worked\n",
    "\n",
    "df['total_earned'] = df.apply(total_earned, axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f48446",
   "metadata": {},
   "source": [
    "## Renaming Columns\n",
    "\n",
    "When we get our data from other sources, we often want to change the column names. For example, we might want all of the column names to follow variable name rules, so that we can use `df.column_name` (which tab-completes) rather than `df['column_name']` (which takes up extra space).\n",
    "\n",
    "You can change all of the column names at once by setting the `.columns` property to a different list. This is great when you need to change all of the column names at once, but be careful! You can easily mislabel columns if you get the ordering wrong. Here’s an example:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame({\n",
    "    'name': ['John', 'Jane', 'Sue', 'Fred'],\n",
    "    'age': [23, 29, 21, 18]\n",
    "})\n",
    "df.columns = ['First Name', 'Age']\n",
    "\n",
    "```\n",
    "\n",
    "This command edits the **existing** DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d697817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                                      Title Category  Year Released  \\\n",
      "0   1                                     Avatar   action           2009   \n",
      "1   2                             Jurassic World   action           2015   \n",
      "2   3                               The Avengers   action           2012   \n",
      "3   4                            The Dark Knight   action           2008   \n",
      "4   5  Star Wars: Episode I - The Phantom Menace   action           1999   \n",
      "\n",
      "   Rating  \n",
      "0     7.9  \n",
      "1     7.3  \n",
      "2     8.1  \n",
      "3     9.0  \n",
      "4     6.6  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('imdb.csv')\n",
    "\n",
    "df.columns = ['ID', 'Title', 'Category', 'Year Released', 'Rating']\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c704fd9c",
   "metadata": {},
   "source": [
    "- You also can rename individual columns by using the `.rename` method.\n",
    "- Pass a dictionary to the `columns` keyword argument.\n",
    "- Using `rename` with only the `columns` keyword will create a **new** DataFrame, leaving your original DataFrame unchanged.\n",
    "- Using `inplace=True` lets us edit the original DataFrame.\n",
    "\n",
    "There are several reasons why `.rename` is preferable to `.columns`:\n",
    "\n",
    "- You can rename just one column\n",
    "- You can be specific about which column names are getting changed (with `.column` you can accidentally switch column names if you’re not careful)\n",
    "\n",
    "**Note:** If you misspell one of the original column names, this command won’t fail. It just won’t change anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ca52140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                movie_title   genre  year  imdb_rating\n",
      "0   1                                     Avatar  action  2009          7.9\n",
      "1   2                             Jurassic World  action  2015          7.3\n",
      "2   3                               The Avengers  action  2012          8.1\n",
      "3   4                            The Dark Knight  action  2008          9.0\n",
      "4   5  Star Wars: Episode I - The Phantom Menace  action  1999          6.6\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('imdb.csv')\n",
    "df.rename(columns={'name': 'movie_title'}, inplace=True)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0b0976e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Number 0: id\n",
      "Column Number 1: movie_title\n",
      "Column Number 2: genre\n",
      "Column Number 3: year\n",
      "Column Number 4: imdb_rating\n"
     ]
    }
   ],
   "source": [
    "my_cols = df.columns\n",
    "for i in range(len(my_cols)):\n",
    "    print(f'Column Number {i}: {my_cols[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f239e409",
   "metadata": {},
   "source": [
    "# Aggregates in Pandas\n",
    "\n",
    "An aggregate statistic is a way of creating a single number that describes a group of numbers. Common aggregate statistics include mean, median, and standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aef4d26",
   "metadata": {},
   "source": [
    "## Calculating Column Statistics\n",
    "\n",
    "Aggregate functions summarize many data points (i.e., a column of a dataframe) into a smaller set of values.\n",
    "\n",
    "The general syntax for these calculations is:\n",
    "\n",
    "```\n",
    "df.column_name.command()\n",
    "```\n",
    "Some common commands:\n",
    "\n",
    "- `mean` - Average of all values in column\n",
    "- `std` -\tStandard deviation\n",
    "- `median` - Median\n",
    "- `max` - Maximum value in column\n",
    "- `min` - Minimum value in column\n",
    "- `count` - Number of values in column\n",
    "- `nunique` - Number of unique values in column\n",
    "- `unique` - List of unique values in column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab896f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99 entries, 0 to 98\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             99 non-null     int64  \n",
      " 1   first_name     99 non-null     object \n",
      " 2   last_name      99 non-null     object \n",
      " 3   email          99 non-null     object \n",
      " 4   shoe_type      99 non-null     object \n",
      " 5   shoe_material  99 non-null     object \n",
      " 6   shoe_color     99 non-null     object \n",
      " 7   price          98 non-null     float64\n",
      "dtypes: float64(1), int64(1), object(6)\n",
      "memory usage: 6.3+ KB\n",
      "None\n",
      "Price of the most expensive pair of shoes: $493.0\n",
      "Number of unique colors: 5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "orders = pd.read_csv('orders_shoes.csv')\n",
    "most_expensive = orders.price.max()\n",
    "num_colors = orders.shoe_color.nunique()\n",
    "print(orders.info())\n",
    "print(f'Price of the most expensive pair of shoes: ${most_expensive}')\n",
    "print(f'Number of unique colors: {num_colors}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fa2654",
   "metadata": {},
   "source": [
    "## Calculating Aggregate Functions\n",
    "\n",
    "When we have a bunch of data, we often want to calculate aggregate statistics (mean, standard deviation, median, percentiles, etc.) over certain subsets of the data.\n",
    "\n",
    "Suppose we have a grade book with columns `student`, `assignment_name`, and `grade`. The first few lines look like this:\n",
    "\n",
    "```\n",
    "student\tassignment_name\tgrade\n",
    "Amy\tAssignment 1\t75\n",
    "Amy\tAssignment 2\t35\n",
    "Bob\tAssignment 1\t99\n",
    "Bob\tAssignment 2\t35\n",
    "…\t\t\n",
    "```\n",
    "We want to get an average grade for each student across all assignments. We could do some sort of loop, but Pandas gives us a much easier option: the method `.groupby`.\n",
    "\n",
    "For this example, we’d use the following command:\n",
    "\n",
    "```python\n",
    "grades = df.groupby('student').grade.mean()\n",
    "```\n",
    "\n",
    "The output might look something like this:\n",
    "\n",
    "```\n",
    "student\tgrade\n",
    "Amy\t80\n",
    "Bob\t90\n",
    "Chris\t75\n",
    "…\n",
    "```\n",
    "\n",
    "In general, we use the following syntax to calculate aggregates:\n",
    "\n",
    "```python\n",
    "df.groupby('column1').column2.measurement()\n",
    "```\n",
    "\n",
    "where:\n",
    "\n",
    "- `column1` is the column that we want to group by (`'student'` in our example)\n",
    "- `column2` is the column that we want to perform a measurement on (`grade` in our example)\n",
    "- `measurement` is the measurement function we want to apply (`mean` in our example)\n",
    "\n",
    "\n",
    "For more on the groupby method, review the <a href='https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html#pandas.DataFrame.groupby' target='_blank'>pandas documentation</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a5d4c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "\n",
      "       id first_name    last_name                      email     shoe_type  \\\n",
      "0   41874       Kyle         Peck       KylePeck71@gmail.com  ballet flats   \n",
      "1   31349  Elizabeth    Velazquez   EVelazquez1971@gmail.com         boots   \n",
      "2   43416      Keith     Saunders           KS4047@gmail.com       sandals   \n",
      "3   56054       Ryan      Sweeney  RyanSweeney14@outlook.com       sandals   \n",
      "4   77402      Donna  Blankenship           DB3807@gmail.com     stilettos   \n",
      "..    ...        ...          ...                        ...           ...   \n",
      "94  21506      Scott       Deleon     Scott.Deleon@gmail.com     stilettos   \n",
      "95  77266    Zachary      Gregory  Zachary.Gregory@gmail.com       sandals   \n",
      "96  67264   Danielle      Merrill     DMerrill1998@gmail.com        wedges   \n",
      "97  19100   Danielle       Barron      DBarron1982@gmail.com       sandals   \n",
      "98  26210    Marilyn        Finch   MarilynFinch92@gmail.com       sandals   \n",
      "\n",
      "   shoe_material shoe_color  price  \n",
      "0   faux-leather      black  385.0  \n",
      "1         fabric      brown  388.0  \n",
      "2        leather       navy  346.0  \n",
      "3         fabric      brown  344.0  \n",
      "4         fabric      brown  289.0  \n",
      "..           ...        ...    ...  \n",
      "94        fabric      black  374.0  \n",
      "95       leather        red  216.0  \n",
      "96  faux-leather        red  461.0  \n",
      "97       leather      white  313.0  \n",
      "98       leather      black    NaN  \n",
      "\n",
      "[99 rows x 8 columns]\n",
      "\n",
      "Pricey Shoes:\n",
      "\n",
      "shoe_type\n",
      "ballet flats    481.0\n",
      "boots           478.0\n",
      "clogs           493.0\n",
      "sandals         456.0\n",
      "stilettos       487.0\n",
      "wedges          461.0\n",
      "Name: price, dtype: float64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "pricey_shoes = orders.groupby('shoe_type').price.max()\n",
    "print('Original Data:\\n')\n",
    "print(orders)\n",
    "print('\\nPricey Shoes:\\n')\n",
    "print(pricey_shoes)\n",
    "print(type(pricey_shoes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6473cb10",
   "metadata": {},
   "source": [
    "After using groupby, we often need to clean our resulting data.\n",
    "The `groupby` function creates a new Series, not a DataFrame. For our ShoeFly.com example, the indices of the Series were different values of `shoe_type`, and the name property was `price`.\n",
    "\n",
    "Usually, we’d prefer that those indices were actually a column. In order to get that, we can use `reset_index()`. This will transform our Series into a DataFrame and move the indices into their own column.\n",
    "\n",
    "Generally, you’ll always see a `groupby` statement followed by `reset_index`:\n",
    "\n",
    "```python\n",
    "df.groupby('column1').column2.measurement().reset_index()\n",
    "```\n",
    "\n",
    "When we use groupby, we often want to rename the column we get as a result. Remember that we can rename columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f285e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      shoe_type  price\n",
      "0  ballet flats  481.0\n",
      "1         boots  478.0\n",
      "2         clogs  493.0\n",
      "3       sandals  456.0\n",
      "4     stilettos  487.0\n",
      "5        wedges  461.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "      shoe_type  max price\n",
      "0  ballet flats      481.0\n",
      "1         boots      478.0\n",
      "2         clogs      493.0\n",
      "3       sandals      456.0\n",
      "4     stilettos      487.0\n",
      "5        wedges      461.0\n"
     ]
    }
   ],
   "source": [
    "pricey_shoes = orders.groupby('shoe_type').price.max().reset_index()\n",
    "print(pricey_shoes)\n",
    "print(type(pricey_shoes))\n",
    "\n",
    "pricey_shoes = pricey_shoes.rename(columns={'price':'max price'})\n",
    "print(pricey_shoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dcee11",
   "metadata": {},
   "source": [
    "Sometimes, the operation that you want to perform is more complicated than `mean` or `count`. In those cases, you can use the `apply` method and lambda functions, just like we did for individual column operations. Note that the input to our lambda function will always be a list of values.\n",
    "\n",
    "A great example of this is calculating percentiles. Suppose we have a DataFrame of employee information called `df` that has the following columns:\n",
    "\n",
    "- `id`: the employee’s id number\n",
    "- `name`: the employee’s name\n",
    "- `wage`: the employee’s hourly wage\n",
    "- `category`: the type of work that the employee does\n",
    "\n",
    "Our data might look something like this:\n",
    "\n",
    "```\n",
    "id\t    name        \twage   \tcategory\n",
    "10131\tSarah Carney\t39\t    product\n",
    "14189\tHeather Carey\t17\t    design\n",
    "15004\tGary Mercado\t33\t    marketing\n",
    "11204\tCora Copaz\t    27\t    design\n",
    "…\t\t\t\n",
    "\n",
    "```\n",
    "If we want to calculate the 75th percentile (i.e., the point at which 75% of employees have a lower wage and 25% have a higher wage) for each `category`, we can use the following combination of `apply` and a lambda function:\n",
    "\n",
    "```python\n",
    "# np.percentile can calculate any percentile over an array of values\n",
    "high_earners = df.groupby('category').wage.apply(lambda x: np.percentile(x, 75)).reset_index()\n",
    "```\n",
    "\n",
    "The output, high_earners might look like this:\n",
    "\n",
    "```\n",
    "    category    wage\n",
    "0\tdesign\t    23\n",
    "1\tmarketing\t35\n",
    "2\tproduct\t    48\n",
    "…\t\t\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e598794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  shoe_color  price\n",
      "0      black    NaN\n",
      "1      brown  193.5\n",
      "2       navy  205.5\n",
      "3        red  250.0\n",
      "4      white  196.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "cheap_shoes = orders.groupby('shoe_color').price.apply(lambda x: np.percentile(x, 25)).reset_index()\n",
    "\n",
    "print(cheap_shoes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f444c9d",
   "metadata": {},
   "source": [
    "Sometimes, we want to group by more than one column. We can easily do this by passing a list of column names into the `groupby` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f1342ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       shoe_type shoe_color  quantity\n",
      "0   ballet flats      black         2\n",
      "1   ballet flats      brown         5\n",
      "2   ballet flats        red         3\n",
      "3   ballet flats      white         5\n",
      "4          boots      black         3\n",
      "5          boots      brown         5\n",
      "6          boots       navy         6\n",
      "7          boots        red         2\n",
      "8          boots      white         3\n",
      "9          clogs      black         4\n",
      "10         clogs      brown         6\n",
      "11         clogs       navy         1\n",
      "12         clogs        red         4\n",
      "13         clogs      white         1\n",
      "14       sandals      black         1\n",
      "15       sandals      brown         4\n",
      "16       sandals       navy         5\n",
      "17       sandals        red         3\n",
      "18       sandals      white         4\n",
      "19     stilettos      black         5\n",
      "20     stilettos      brown         3\n",
      "21     stilettos       navy         2\n",
      "22     stilettos        red         2\n",
      "23     stilettos      white         2\n",
      "24        wedges      black         3\n",
      "25        wedges      brown         4\n",
      "26        wedges       navy         4\n",
      "27        wedges        red         5\n",
      "28        wedges      white         2\n"
     ]
    }
   ],
   "source": [
    "shoe_counts = orders.groupby(['shoe_type', 'shoe_color']).id.count().reset_index()\n",
    "\n",
    "shoe_counts = shoe_counts.rename(columns={'id': 'quantity'})\n",
    "\n",
    "print(shoe_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8100c91",
   "metadata": {},
   "source": [
    "## Pivot Tables\n",
    "\n",
    "When we perform a `groupby` across multiple columns, we often want to change how our data is stored. For instance, recall the example where we are running a chain of stores and have data about the number of sales at different locations on different days:\n",
    "\n",
    "```\n",
    "Location\tDate\tDay of Week\tTotal Sales\n",
    "West Village\tFebruary 1\tW\t400\n",
    "West Village\tFebruary 2\tTh\t450\n",
    "Chelsea\tFebruary 1\tW\t375\n",
    "Chelsea\tFebruary 2\tTh\t390\n",
    "\n",
    "```\n",
    "We suspected that there might be different sales on different days of the week at different stores, so we performed a groupby across two different columns (Location and Day of Week). This gave us results that looked like this:\t\t\n",
    "```\n",
    "\n",
    "Location\tDay of Week\tTotal Sales\n",
    "Chelsea\tM\t300\n",
    "Chelsea\tTu\t310\n",
    "Chelsea\tW\t320\n",
    "Chelsea\tTh\t290\n",
    "…\t\t\n",
    "West Village\tTh\t400\n",
    "West Village\tF\t390\n",
    "West Village\tSa\t250\n",
    "…\t\t\n",
    "\n",
    "```\n",
    "\n",
    "In order to test our hypothesis, it would be more useful if the table was formatted like this:\t\t\n",
    "```\n",
    "Location\t    M\tTu\tW\tTh\tF\tSa\tSu\n",
    "Chelsea\t        400\t390\t250\t275\t300\t150\t175\n",
    "West Village\t300\t310\t350\t400\t390\t250\t200\n",
    "…\t\t\t\t\t\t\t\n",
    "\n",
    "```\n",
    "\n",
    "Reorganizing a table in this way is called **pivoting**. The new table is called a **pivot table**.\n",
    "\n",
    "In Pandas, the command for pivot is:\n",
    "\n",
    "```python\n",
    "df.pivot(columns='ColumnToPivot',\n",
    "         index='ColumnToBeRows',\n",
    "         values='ColumnToBeValues')\n",
    "\n",
    "```\n",
    "\n",
    "For our specific example, we would write the command like this:\n",
    "\n",
    "```python\n",
    "# First use the groupby statement:\n",
    "unpivoted = df.groupby(['Location', 'Day of Week'])['Total Sales'].mean().reset_index()\n",
    "# Now pivot the table\n",
    "pivoted = unpivoted.pivot(\n",
    "    columns='Day of Week',\n",
    "    index='Location',\n",
    "    values='Total Sales')\n",
    "\n",
    "```\n",
    "\n",
    "Just like with `groupby`, the output of a pivot command is a new DataFrame, but the indexing tends to be “weird”, so we usually follow up with `.reset_index()`.\n",
    "\n",
    "For more on the pivot function, <a href='https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html' target='_blank'>see the pandas documentation</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12e17528",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'product':['Brownies', 'Cupcakes', 'Cupcakes', 'Cupcakes', 'Brownies', 'Brownies', 'Galletas', 'Galletas', 'Cupcakes', 'Galletas', 'Cupcakes', 'Brownies', 'Cupcakes', 'Brownies', 'Cupcakes'],\n",
    "                   'local':  ['Norte', 'Sur', 'Sur', 'Sur', 'Sur', 'Sur', 'Norte', 'Norte', 'Sur', 'Sur', 'Norte', 'Norte', 'Sur', 'Norte', 'Norte'],\n",
    "                   'Q': [1, 3, 4, 6, 7, 9, 3, 5, 10, 15, 4, 1, 3, 12, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1e29565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>local</th>\n",
       "      <th>Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brownies</td>\n",
       "      <td>Norte</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cupcakes</td>\n",
       "      <td>Sur</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cupcakes</td>\n",
       "      <td>Sur</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cupcakes</td>\n",
       "      <td>Sur</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brownies</td>\n",
       "      <td>Sur</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Brownies</td>\n",
       "      <td>Sur</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Galletas</td>\n",
       "      <td>Norte</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Galletas</td>\n",
       "      <td>Norte</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cupcakes</td>\n",
       "      <td>Sur</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Galletas</td>\n",
       "      <td>Sur</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cupcakes</td>\n",
       "      <td>Norte</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Brownies</td>\n",
       "      <td>Norte</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cupcakes</td>\n",
       "      <td>Sur</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Brownies</td>\n",
       "      <td>Norte</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cupcakes</td>\n",
       "      <td>Norte</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     product  local   Q\n",
       "0   Brownies  Norte   1\n",
       "1   Cupcakes    Sur   3\n",
       "2   Cupcakes    Sur   4\n",
       "3   Cupcakes    Sur   6\n",
       "4   Brownies    Sur   7\n",
       "5   Brownies    Sur   9\n",
       "6   Galletas  Norte   3\n",
       "7   Galletas  Norte   5\n",
       "8   Cupcakes    Sur  10\n",
       "9   Galletas    Sur  15\n",
       "10  Cupcakes  Norte   4\n",
       "11  Brownies  Norte   1\n",
       "12  Cupcakes    Sur   3\n",
       "13  Brownies  Norte  12\n",
       "14  Cupcakes  Norte   5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd66d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpivot = df.groupby(['product', 'local']).Q.sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3de30461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>local</th>\n",
       "      <th>Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brownies</td>\n",
       "      <td>Norte</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brownies</td>\n",
       "      <td>Sur</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cupcakes</td>\n",
       "      <td>Norte</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cupcakes</td>\n",
       "      <td>Sur</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Galletas</td>\n",
       "      <td>Norte</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Galletas</td>\n",
       "      <td>Sur</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    product  local   Q\n",
       "0  Brownies  Norte  14\n",
       "1  Brownies    Sur  16\n",
       "2  Cupcakes  Norte   9\n",
       "3  Cupcakes    Sur  26\n",
       "4  Galletas  Norte   8\n",
       "5  Galletas    Sur  15"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "098de31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pivot = unpivot.pivot(columns='local', index='product', values='Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a5bca94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>local</th>\n",
       "      <th>Norte</th>\n",
       "      <th>Sur</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Brownies</th>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cupcakes</th>\n",
       "      <td>9</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Galletas</th>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "local     Norte  Sur\n",
       "product             \n",
       "Brownies     14   16\n",
       "Cupcakes      9   26\n",
       "Galletas      8   15"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8689c0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "norte = df[df.local == 'Norte'].Q.sum()\n",
    "sur = df[df.local == 'Sur'].Q.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "265a83f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b848f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0508d94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shoe_color     shoe_type  black  brown  navy  red  white\n",
      "0           ballet flats    2.0    5.0   NaN  3.0    5.0\n",
      "1                  boots    3.0    5.0   6.0  2.0    3.0\n",
      "2                  clogs    4.0    6.0   1.0  4.0    1.0\n",
      "3                sandals    1.0    4.0   5.0  3.0    4.0\n",
      "4              stilettos    5.0    3.0   2.0  2.0    2.0\n",
      "5                 wedges    3.0    4.0   4.0  5.0    2.0\n"
     ]
    }
   ],
   "source": [
    "shoe_counts = orders.groupby(['shoe_type', 'shoe_color']).id.count().reset_index()\n",
    "\n",
    "shoe_counts_pivot = shoe_counts.pivot(columns='shoe_color', index='shoe_type', values='id').reset_index()\n",
    "\n",
    "print(shoe_counts_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1d5f882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Visits: \n",
      "      id first_name last_name                       email         month  \\\n",
      "0  10043      Louis      Koch       LouisKoch43@gmail.com     3 - March   \n",
      "1  10150      Bruce      Webb     BruceWebb44@outlook.com     3 - March   \n",
      "2  10155   Nicholas   Hoffman  Nicholas.Hoffman@gmail.com  2 - February   \n",
      "3  10178    William       Key     William.Key@outlook.com     3 - March   \n",
      "4  10208      Karen      Bass            KB4971@gmail.com  2 - February   \n",
      "\n",
      "  utm_source  \n",
      "0      yahoo  \n",
      "1    twitter  \n",
      "2     google  \n",
      "3      yahoo  \n",
      "4     google  \n",
      "\n",
      "Click source: \n",
      "  utm_source  counts\n",
      "0      email     462\n",
      "1   facebook     823\n",
      "2     google     543\n",
      "3    twitter     415\n",
      "4      yahoo     757\n",
      "\n",
      "Click source by month: \n",
      "month utm_source  1 - January  2 - February  3 - March\n",
      "0          email           43           147        272\n",
      "1       facebook          404           263        156\n",
      "2         google          127           196        220\n",
      "3        twitter          164           154         97\n",
      "4          yahoo          262           240        255\n"
     ]
    }
   ],
   "source": [
    "user_visits = pd.read_csv('page_visits.csv')\n",
    "\n",
    "print(f'User Visits: \\n{user_visits.head()}\\n')\n",
    "\n",
    "click_source = user_visits.groupby('utm_source').id.count().reset_index()\n",
    "click_source.rename(columns={'id':'counts'}, inplace=True)\n",
    "\n",
    "print(f'Click source: \\n{click_source}\\n')\n",
    "\n",
    "click_source_by_month = user_visits.groupby(['utm_source', 'month']).id.count().reset_index()\n",
    "\n",
    "click_source_by_month_pivot = click_source_by_month.pivot(columns='month', index='utm_source', values='id').reset_index()\n",
    "\n",
    "print(f'Click source by month: \\n{click_source_by_month_pivot}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e61a0e",
   "metadata": {},
   "source": [
    "# Working with Multiple DataFrames\n",
    "\n",
    "In order to efficiently store data, we often spread related information across multiple tables.\n",
    "\n",
    "For instance, imagine that we own an e-commerce business and we want to track the products that have been ordered from our website.\n",
    "\n",
    "We could have one table with all of the following information:\n",
    "\n",
    "- `order_id`\n",
    "- `customer_id`\n",
    "- `customer_name`\n",
    "- `customer_address`\n",
    "- `customer_phone_number`\n",
    "- `product_id`\n",
    "- `product_description`\n",
    "- `product_price`\n",
    "- `quantity`\n",
    "- `timestamp`\n",
    "\n",
    "However, a lot of this information would be repeated. If the same customer makes multiple orders, that customer’s name, address, and phone number will be reported multiple times. If the same product is ordered by multiple customers, then the product price and description will be repeated. This will make our orders table big and unmanageable.\n",
    "\n",
    "So instead, we can split our data into three tables:\n",
    "\n",
    "- `orders` would contain the information necessary to describe an order: `order_id`, `customer_id`, `product_id`, `quantity`, and `timestamp`\n",
    "- `products` would contain the information to describe each product: `product_id`, `product_description` and `product_price`\n",
    "- `customers` would contain the information for each customer: `customer_id`, `customer_name`, `customer_address`, and `customer_phone_number`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3284e2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8 entries, 0 to 7\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   order_id     8 non-null      int64 \n",
      " 1   customer_id  8 non-null      int64 \n",
      " 2   product_id   8 non-null      int64 \n",
      " 3   quantity     8 non-null      int64 \n",
      " 4   timestamp    8 non-null      object\n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 448.0+ bytes\n",
      "\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4 entries, 0 to 3\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   product_id   4 non-null      int64 \n",
      " 1   description  4 non-null      object\n",
      " 2   price        4 non-null      int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 224.0+ bytes\n",
      "\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   customer_id    3 non-null      int64 \n",
      " 1   customer_name  3 non-null      object\n",
      " 2   address        3 non-null      object\n",
      " 3   phone_number   3 non-null      object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 224.0+ bytes\n",
      "\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "orders = pd.read_csv('orders.csv')\n",
    "products = pd.read_csv('products.csv')\n",
    "customers = pd.read_csv('customers.csv')\n",
    "\n",
    "print(f'\\n{orders.info()}\\n')\n",
    "print(f'\\n{products.info()}\\n')\n",
    "print(f'\\n{customers.info()}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b528df3",
   "metadata": {},
   "source": [
    "## Inner Merge\n",
    "\n",
    "Suppose we have the following three tables that describe our eCommerce business:\n",
    "\n",
    "- `orders` — a table with information on each transaction\n",
    "- `products` — a table with product IDs, descriptions, and prices\n",
    "- `customers` — a table with customer names and contact information\n",
    "\n",
    "If we just look at the orders table, we can’t really tell what’s happened in each order. However, if we refer to the other tables, we can get a more complete picture.\n",
    "\n",
    "Matching two DataFrames is called **merging**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3fe4af",
   "metadata": {},
   "source": [
    "The `.merge()` method looks for columns that are common between two DataFrames and then looks for rows where those column’s values are the same. It then combines the matching rows into a single row in a new table.\n",
    "\n",
    "We can call the `pd.merge()` method with two tables like this:\n",
    "\n",
    "```python\n",
    "new_df = pd.merge(orders, customers)\n",
    "```\n",
    "\n",
    "This will match up all of the customer information to the orders that each customer made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba534bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales:\n",
      "      month  revenue\n",
      "0   January      300\n",
      "1  February      290\n",
      "2     March      310\n",
      "3     April      325\n",
      "4       May      475\n",
      "5      June      495\n",
      "Targets:\n",
      "      month  target\n",
      "0   January     310\n",
      "1  February     270\n",
      "2     March     300\n",
      "3     April     350\n",
      "4       May     475\n",
      "5      June     500\n",
      "Sales vs Targets:\n",
      "      month  revenue  target\n",
      "0   January      300     310\n",
      "1  February      290     270\n",
      "2     March      310     300\n",
      "3     April      325     350\n",
      "4       May      475     475\n",
      "5      June      495     500\n",
      "Crushing Months:\n",
      "      month  revenue  target\n",
      "1  February      290     270\n",
      "2     March      310     300\n"
     ]
    }
   ],
   "source": [
    "sales = pd.read_csv('sales.csv')\n",
    "print('Sales:')\n",
    "print(sales)\n",
    "targets = pd.read_csv('targets.csv')\n",
    "print('Targets:')\n",
    "print(targets)\n",
    "\n",
    "sales_vs_targets = pd.merge(sales, targets)\n",
    "print('Sales vs Targets:')\n",
    "print(sales_vs_targets)\n",
    "\n",
    "crushing_it = sales_vs_targets[sales_vs_targets.revenue > sales_vs_targets.target]\n",
    "print('Crushing Months:')\n",
    "print(crushing_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "403f375c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estudiantes: \n",
      "\n",
      "   Student ID Student Name   Color\n",
      "0           1         Alex    blue\n",
      "1           2       Brayan   green\n",
      "2           3    Stephanie  yellow\n",
      "3           4       Néstor     red\n",
      "4           5        Jorge   black\n",
      "\n",
      "Notas: \n",
      "\n",
      "    Activity  Student ID  Grade\n",
      "0          1           1    3.9\n",
      "1          1           2    2.5\n",
      "2          1           3    4.5\n",
      "3          1           4    2.4\n",
      "4          1           5    3.7\n",
      "5          2           1    1.4\n",
      "6          2           2    4.5\n",
      "7          2           3    2.4\n",
      "8          2           4    3.4\n",
      "9          2           5    1.2\n",
      "10         3           1    3.4\n",
      "11         3           2    3.3\n",
      "12         3           3    4.2\n",
      "13         3           4    3.8\n",
      "14         3           5    2.3\n"
     ]
    }
   ],
   "source": [
    "students = pd.DataFrame({\n",
    "  'Student ID': [1, 2, 3, 4, 5],\n",
    "  'Student Name': ['Alex', 'Brayan', 'Stephanie', 'Néstor', 'Jorge'],\n",
    "  'Color': ['blue', 'green', 'yellow', 'red', 'black']\n",
    "})\n",
    "\n",
    "grades = pd.DataFrame({\n",
    "  'Activity': [1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3],\n",
    "  'Student ID': [1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5],\n",
    "  'Grade': [3.9, 2.5, 4.5, 2.4, 3.7, 1.4, 4.5, 2.4, 3.4, 1.2, 3.4, 3.3, 4.2, 3.8, 2.3]\n",
    "})\n",
    "\n",
    "print('Estudiantes: \\n')\n",
    "print(students)\n",
    "print('\\nNotas: \\n')\n",
    "print(grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1c583b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(grades, students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31ff67cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Student Name</th>\n",
       "      <th>Color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Alex</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Alex</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Alex</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Brayan</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Brayan</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Brayan</td>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Stephanie</td>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Néstor</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>Néstor</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Néstor</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>Jorge</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Jorge</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Jorge</td>\n",
       "      <td>black</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Activity  Student ID  Grade Student Name   Color\n",
       "0          1           1    3.9         Alex    blue\n",
       "1          2           1    1.4         Alex    blue\n",
       "2          3           1    3.4         Alex    blue\n",
       "3          1           2    2.5       Brayan   green\n",
       "4          2           2    4.5       Brayan   green\n",
       "5          3           2    3.3       Brayan   green\n",
       "6          1           3    4.5    Stephanie  yellow\n",
       "7          2           3    2.4    Stephanie  yellow\n",
       "8          3           3    4.2    Stephanie  yellow\n",
       "9          1           4    2.4       Néstor     red\n",
       "10         2           4    3.4       Néstor     red\n",
       "11         3           4    3.8       Néstor     red\n",
       "12         1           5    3.7        Jorge   black\n",
       "13         2           5    1.2        Jorge   black\n",
       "14         3           5    2.3        Jorge   black"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a45509a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades_means = new_df.groupby(['Student Name']).Grade.mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7d16ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student Name</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alex</td>\n",
       "      <td>2.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brayan</td>\n",
       "      <td>3.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jorge</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Néstor</td>\n",
       "      <td>3.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stephanie</td>\n",
       "      <td>3.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Student Name     Grade\n",
       "0         Alex  2.900000\n",
       "1       Brayan  3.433333\n",
       "2        Jorge  2.400000\n",
       "3       Néstor  3.200000\n",
       "4    Stephanie  3.700000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades_means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5dc2da",
   "metadata": {},
   "source": [
    "In addition to using `pd.merge()`, each DataFrame has its own `.merge()` method. For instance, if you wanted to merge `orders` with `customers`, you could use:\n",
    "\n",
    "```python\n",
    "new_df = orders.merge(customers)\n",
    "```\n",
    "\n",
    "This produces the same DataFrame as if we had called `pd.merge(orders, customers)`.\n",
    "\n",
    "We generally use this when we are joining more than two DataFrames together because we can “chain” the commands. The following command would merge orders to customers, and then the resulting DataFrame to products:\n",
    "\n",
    "```python\n",
    "big_df = orders.merge(customers).merge(products)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f0afa972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      month  revenue  target  men  women\n",
      "0   January      300     310   30     35\n",
      "1  February      290     270   29     35\n",
      "2     March      310     300   31     29\n",
      "3     April      325     350   32     28\n",
      "4       May      475     475   47     50\n",
      "5      June      495     500   49     45\n",
      "      month  revenue  target  men  women\n",
      "1  February      290     270   29     35\n"
     ]
    }
   ],
   "source": [
    "men_women = pd.read_csv('men_women_sales.csv')\n",
    "\n",
    "all_data = sales.merge(targets).merge(men_women)\n",
    "\n",
    "print(all_data)\n",
    "\n",
    "results = all_data[(all_data.revenue > all_data.target) & (all_data.women > all_data.men)]\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c39cf84",
   "metadata": {},
   "source": [
    "## Merge on Specific Columns\n",
    "\n",
    "In the previous example, the `.merge()` function “knew” how to combine tables based on the columns that were the same between two tables. For instance, `products` and `orders` both had a column called product_id. This won’t always be true when we want to perform a merge.\n",
    "\n",
    "Generally, the `products` and `customers` DataFrames would not have the columns `product_id` or `customer_id`. Instead, they would both be called `id` and it would be implied that the id was the `product_id` for the products table and `customer_id` for the `customers` table. \n",
    "\n",
    "### How would this affect our merges?\n",
    "\n",
    "Because the `id` columns would mean something different in each table, our default merges would be wrong.\n",
    "\n",
    "One way that we could address this problem is to use `.rename()` to rename the columns for our merges. In the example below, we will rename the column `id` to `customer_id`, so that `orders` and `customers` have a common column for the merge.\n",
    "\n",
    "\n",
    "```\n",
    "pd.merge(orders, customers.rename(columns={'id': 'customer_id'}))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "520bca05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  customer_id  product_id  quantity   timestamp  \\\n",
      "0         1            2           3         1  2017-01-01   \n",
      "1         5            3           3         3  2017-02-01   \n",
      "2         2            2           2         3  2017-01-01   \n",
      "3         4            3           2         2  2017-02-01   \n",
      "4         3            3           1         1  2017-01-01   \n",
      "5         7            1           1         1  2017-02-02   \n",
      "6         6            1           4         2  2017-03-01   \n",
      "7         8            1           4         1  2017-02-02   \n",
      "\n",
      "          description  price  \n",
      "0          doo-hickey      7  \n",
      "1          doo-hickey      7  \n",
      "2  whatcha-ma-call-it     10  \n",
      "3  whatcha-ma-call-it     10  \n",
      "4      thing-a-ma-jig      5  \n",
      "5      thing-a-ma-jig      5  \n",
      "6               gizmo      3  \n",
      "7               gizmo      3  \n"
     ]
    }
   ],
   "source": [
    "orders_products = orders.merge(products.rename(columns={'id': 'product_id'}))\n",
    "\n",
    "print(orders_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607fcd30",
   "metadata": {},
   "source": [
    "If we don’t want to rename, we have another option. We could use the keywords `left_on` and `right_on` to specify which columns we want to perform the merge on. In the example below, the “left” table is the one that comes first (`orders`), and the “right” table is the one that comes second (`customers`). This syntax says that we should match the `customer_id` from orders to the `id` in customers.\n",
    "\n",
    "```python\n",
    "pd.merge(\n",
    "    orders,\n",
    "    customers,\n",
    "    left_on='customer_id',\n",
    "    right_on='id')\n",
    "\n",
    "```\n",
    "\n",
    "If we use this syntax, we’ll end up with two columns called id, one from the first table and one from the second. Pandas won’t let you have two columns with the same name, so it will change them to id_x and id_y.\n",
    "\n",
    "The new column names `id_x` and `id_y` aren’t very helpful for us when we read the table. We can help make them more useful by using the keyword suffixes. We can provide a list of suffixes to use instead of “_x” and “_y”.\n",
    "\n",
    "For example, we could use the following code to make the suffixes reflect the table names:\n",
    "\n",
    "```python\n",
    "pd.merge(\n",
    "    orders,\n",
    "    customers,\n",
    "    left_on='customer_id',\n",
    "    right_on='id',\n",
    "    suffixes=['_order', '_customer']\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "626a6e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders:\n",
      "   id  customer_id  product_id  quantity   timestamp\n",
      "0   1            2           3         1  2017-01-01\n",
      "1   2            2           2         3  2017-01-01\n",
      "2   3            3           1         1  2017-01-01\n",
      "3   4            3           2         2  2017-02-01\n",
      "4   5            3           3         3  2017-02-01\n",
      "5   6            1           4         2  2017-03-01\n",
      "6   7            1           1         1  2017-02-02\n",
      "7   8            1           4         1  2017-02-02\n",
      "\n",
      "Products:\n",
      "   id         description  price\n",
      "0   1      thing-a-ma-jig      5\n",
      "1   2  whatcha-ma-call-it     10\n",
      "2   3          doo-hickey      7\n",
      "3   4               gizmo      3\n",
      "\n",
      "Orders with Products:\n",
      "   id_orders  customer_id  product_id  quantity   timestamp  id_products  \\\n",
      "0          1            2           3         1  2017-01-01            3   \n",
      "1          5            3           3         3  2017-02-01            3   \n",
      "2          2            2           2         3  2017-01-01            2   \n",
      "3          4            3           2         2  2017-02-01            2   \n",
      "4          3            3           1         1  2017-01-01            1   \n",
      "5          7            1           1         1  2017-02-02            1   \n",
      "6          6            1           4         2  2017-03-01            4   \n",
      "7          8            1           4         1  2017-02-02            4   \n",
      "\n",
      "          description  price  \n",
      "0          doo-hickey      7  \n",
      "1          doo-hickey      7  \n",
      "2  whatcha-ma-call-it     10  \n",
      "3  whatcha-ma-call-it     10  \n",
      "4      thing-a-ma-jig      5  \n",
      "5      thing-a-ma-jig      5  \n",
      "6               gizmo      3  \n",
      "7               gizmo      3  \n"
     ]
    }
   ],
   "source": [
    "orders.rename(columns={'order_id':'id'}, inplace=True)\n",
    "products.rename(columns={'product_id':'id'}, inplace=True)\n",
    "orders_products = pd.merge(orders,\n",
    "                           products,\n",
    "                           left_on='product_id',\n",
    "                           right_on='id',\n",
    "                           suffixes=['_orders', '_products']\n",
    "                          )\n",
    "print('Orders:')\n",
    "print(orders)\n",
    "print('\\nProducts:')\n",
    "print(products)\n",
    "print('\\nOrders with Products:')\n",
    "print(orders_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da6da33",
   "metadata": {},
   "source": [
    "## Outer Merge\n",
    "\n",
    "When we merge two DataFrames whose rows don’t match perfectly, we lose the unmatched rows.\n",
    "\n",
    "This type of merge (where we only include matching rows) is called an _inner merge_. There are other types of merges that we can use when we want to keep information from the unmatched rows.\n",
    "\n",
    "Suppose that two companies, Company A and Company B have just merged. They each have a list of customers, but they keep slightly different data. Company A has each customer’s name and email. Company B has each customer’s name and phone number. They have some customers in common, but some are different.\n",
    "\n",
    "If we wanted to combine the data from both companies without losing the customers who are missing from one of the tables, we could use an _Outer Join_. An _Outer Join_ would include all rows from both tables, even if they don’t match. Any missing values are filled in with None or nan (which stands for “Not a Number”).\n",
    "\n",
    "```python\n",
    "pd.merge(company_a, company_b, how='outer')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0542d1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store A: \n",
      "          item  store_a_inventory\n",
      "0       hammer                 12\n",
      "1  screwdriver                 15\n",
      "2        nails                200\n",
      "3       screws                350\n",
      "4          saw                  6\n",
      "5    duct tape                150\n",
      "6       wrench                 12\n",
      "7     pvc pipe                 54\n",
      "\n",
      "Store B: \n",
      "            item  store_b_inventory\n",
      "0         hammer                  6\n",
      "1          nails                250\n",
      "2            saw                  6\n",
      "3      duct tape                150\n",
      "4       pvc pipe                 54\n",
      "5           rake                 10\n",
      "6         shovel                 15\n",
      "7  wooden dowels                192\n",
      "\n",
      "Store A & B: \n",
      "             item  store_a_inventory  store_b_inventory\n",
      "0          hammer               12.0                6.0\n",
      "1     screwdriver               15.0                NaN\n",
      "2           nails              200.0              250.0\n",
      "3          screws              350.0                NaN\n",
      "4             saw                6.0                6.0\n",
      "5       duct tape              150.0              150.0\n",
      "6          wrench               12.0                NaN\n",
      "7        pvc pipe               54.0               54.0\n",
      "8            rake                NaN               10.0\n",
      "9          shovel                NaN               15.0\n",
      "10  wooden dowels                NaN              192.0\n"
     ]
    }
   ],
   "source": [
    "store_a = pd.read_csv('store_a.csv')\n",
    "print('Store A: ')\n",
    "print(store_a)\n",
    "\n",
    "store_b = pd.read_csv('store_b.csv')\n",
    "print('\\nStore B: ')\n",
    "print(store_b)\n",
    "\n",
    "store_a_b_outer = pd.merge(store_a, store_b, how='outer')\n",
    "print('\\nStore A & B: ')\n",
    "print(store_a_b_outer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07651dd",
   "metadata": {},
   "source": [
    "## Left and Right Merge\n",
    "\n",
    "Let’s return to the merge of Company A and Company B. Suppose we want to identify which customers are missing phone information. We would want a list of all customers who have `email`, but don’t have `phone`.\n",
    "\n",
    "### Left Merge\n",
    "\n",
    "We could get this by performing a _Left Merge_. A _Left Merge_ includes all rows from the first (left) table, but only rows from the second (right) table that match the first table.\n",
    "\n",
    "For this command, the order of the arguments matters. If the first DataFrame is `company_a` and we do a left join, we’ll only end up with rows that appear in company_a.\n",
    "\n",
    "By listing `company_a` first, we get all customers from Company A, and only customers from Company B who are also customers of Company A.\n",
    "\n",
    "```python\n",
    "pd.merge(company_a, company_b, how='left')\n",
    "```\n",
    "Now let’s say we want a list of all customers who have `phone` but no `email`. We can do this by performing a Right Merge.\n",
    "\n",
    "### Right Merge\n",
    "\n",
    "Right merge is the exact opposite of left merge. Here, the merged table will include all rows from the second (right) table, but only rows from the first (left) table that match the second table.\n",
    "\n",
    "By listing `company_a` first and `company_b` second, we get all customers from Company B, and only customers from Company A who are also customers of Company B.\n",
    "\n",
    "```python\n",
    "pd.merge(company_a, company_b, how=\"right\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8442e7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          item  store_a_inventory  store_b_inventory\n",
      "0       hammer                 12                6.0\n",
      "1  screwdriver                 15                NaN\n",
      "2        nails                200              250.0\n",
      "3       screws                350                NaN\n",
      "4          saw                  6                6.0\n",
      "5    duct tape                150              150.0\n",
      "6       wrench                 12                NaN\n",
      "7     pvc pipe                 54               54.0\n",
      "            item  store_b_inventory  store_a_inventory\n",
      "0         hammer                  6               12.0\n",
      "1          nails                250              200.0\n",
      "2            saw                  6                6.0\n",
      "3      duct tape                150              150.0\n",
      "4       pvc pipe                 54               54.0\n",
      "5           rake                 10                NaN\n",
      "6         shovel                 15                NaN\n",
      "7  wooden dowels                192                NaN\n"
     ]
    }
   ],
   "source": [
    "store_a_b_left = pd.merge(store_a, store_b, how='left')\n",
    "\n",
    "store_b_a_left = pd.merge(store_b, store_a, how='left')\n",
    "\n",
    "print(store_a_b_left)\n",
    "print(store_b_a_left)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb33cf6e",
   "metadata": {},
   "source": [
    "## Concatenate DataFrames\n",
    "\n",
    "Sometimes, a dataset is broken into multiple tables. For instance, data is often split into multiple CSV files so that each download is smaller.\n",
    "\n",
    "When we need to reconstruct a single DataFrame from multiple smaller DataFrames, we can use the method `pd.concat([df1, df2, df3, ...])`. This method only works if all of the columns are the same in all of the DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29900b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bakery: \n",
      "                  item  price\n",
      "0               cookie   2.50\n",
      "1              brownie   3.50\n",
      "2        slice of cake   4.75\n",
      "3  slice of cheesecake   4.75\n",
      "4         slice of pie   5.00\n",
      "\n",
      "Ice Cream: \n",
      "                              item  price\n",
      "0     scoop of chocolate ice cream   3.00\n",
      "1       scoop of vanilla ice cream   2.95\n",
      "2    scoop of strawberry ice cream   3.05\n",
      "3  scoop of cookie dough ice cream   3.25\n",
      "\n",
      "Menu: \n",
      "                              item  price\n",
      "0                           cookie   2.50\n",
      "1                          brownie   3.50\n",
      "2                    slice of cake   4.75\n",
      "3              slice of cheesecake   4.75\n",
      "4                     slice of pie   5.00\n",
      "0     scoop of chocolate ice cream   3.00\n",
      "1       scoop of vanilla ice cream   2.95\n",
      "2    scoop of strawberry ice cream   3.05\n",
      "3  scoop of cookie dough ice cream   3.25\n"
     ]
    }
   ],
   "source": [
    "bakery = pd.read_csv('bakery.csv')\n",
    "print('Bakery: ')\n",
    "print(bakery)\n",
    "ice_cream = pd.read_csv('ice_cream.csv')\n",
    "print('\\nIce Cream: ')\n",
    "print(ice_cream)\n",
    "\n",
    "menu = pd.concat([bakery, ice_cream])\n",
    "print('\\nMenu: ')\n",
    "print(menu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df6bd8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
